{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf27qiQVWX1k"
      },
      "source": [
        "# Generative Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBweIHVAWX1m"
      },
      "source": [
        "# Autoencoders\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "\n",
        "Today we will use `keras` in `tensorflow` to build two autoencoders. \n",
        "\n",
        "We will start with a simple neural network architecture that is composed of an input layer a lower-dimensional latent space, and an output layer of equal size.\n",
        "\n",
        "<img src=\"https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-06-at-3.17.13-PM.png\" width=\"400\" />\n",
        "\n",
        "Autoencoders are an *unsupervised learning* method. We will begin by using an autoencoder to create a latent space representation of the `digits` dataset, a reduced-dimension version of the `MNIST` dataset. Replacing the `digits` dataset with the larger `MNIST` dataset is perhaps a more useful activity, but increases the runtime of the algorithm.\n",
        "\n",
        "We will then extend this to create an autoencoder for the AT-TPC data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adgrSaEiWX1m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn import datasets, cluster # for k-means clustering\n",
        "from sklearn.cluster import KMeans\n",
        "import random # if we want to create a Variational Autoencoder\n",
        "# This is simply an alias for convenience\n",
        "layers = tf.keras.layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtqbZA3jWX1n"
      },
      "outputs": [],
      "source": [
        "# useful functions\n",
        "\n",
        "def load_attpc_data():\n",
        "    \"\"\"Loads in the AT-TPC data.\n",
        "        \n",
        "    Returns:\n",
        "        A tuple of the form ((real_features, real_targets), (simulated_features, simulated_targets))\n",
        "    \"\"\"\n",
        "    simulated_data_origin = 'https://github.com/CompPhysics/MachineLearningMSU/raw/master/Day2_materials/data/simulated-attpc-events.h5'\n",
        "    real_data_origin = 'https://github.com/CompPhysics/MachineLearningMSU/raw/master/Day2_materials/data/real-attpc-events.h5'\n",
        "    \n",
        "    simulated_path = tf.keras.utils.get_file('simulated-attpc-data.h5', origin=simulated_data_origin)\n",
        "    real_path = tf.keras.utils.get_file('real-attpc-data.h5', origin=real_data_origin)\n",
        "    \n",
        "    with h5py.File(simulated_path, 'r') as h5:\n",
        "        simulated_features = h5['features'][:]\n",
        "        simulated_targets = h5['targets'][:]\n",
        "        \n",
        "    with h5py.File(real_path, 'r') as h5:\n",
        "        real_features = h5['features'][:]\n",
        "        real_targets = h5['targets'][:]\n",
        "    \n",
        "    return (real_features, real_targets), (simulated_features, simulated_targets)\n",
        "\n",
        "def plot_learning_curve(history):\n",
        "    \"\"\"Plots a learning curve from a training history.\n",
        "    \n",
        "    Arguments:\n",
        "        history (dict): The training history returned by `model.fit()`.\n",
        "        \n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(11, 6), dpi=100)\n",
        "    plt.plot(history.history['loss'], 'o-', label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], 'o:', color='r', label='Validation Loss')\n",
        "    plt.legend(loc='best')\n",
        "    plt.title('Learning Curve')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xticks(range(0, len(history.history['loss'])), range(1, len(history.history['loss']) + 1))\n",
        "    plt.show()\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1nY4GFxWX1o"
      },
      "source": [
        "## Data exploration\n",
        "\n",
        "As usual, we begin by loading our data, normalizing it, and putting it into the approporate format for our model. In this case, we need 1D arrays for our fully connected architecture. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2MipplvWX1p"
      },
      "outputs": [],
      "source": [
        "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVnkVF3WWX1p"
      },
      "outputs": [],
      "source": [
        "print('Training Features:\\n   Shape: {}\\n   Type: {}\\n'.format(x_train.shape, x_train.dtype))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ6_0yTEWX1q"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cipF2-OSWX1q"
      },
      "source": [
        "### Next, we rescale the data. Here, I rescaled the images to [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmXugx2RWX1q"
      },
      "outputs": [],
      "source": [
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLNHSZxuWX1r"
      },
      "source": [
        "Now we build the autoencoder. Ours is a standard feed-forward neural network architecture with three layers as descibed above.\n",
        "\n",
        "Let's start by reducing our dimensionality by a factor of two and see if we can recover our original images.\n",
        "\n",
        "One way to build an autoencoder is to store each layer into a variable so that we can access the different pieces later. \n",
        "\n",
        "*Note: I achieved my best performance with a `relu` activation function on both the encoded and output layers.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whp80DxEWX1r"
      },
      "outputs": [],
      "source": [
        "latent_dim = 128\n",
        "\n",
        "input_img = layers.Input(shape=(784,))\n",
        "\n",
        "latent_layer = layers.Dense(latent_dim, activation=\"relu\")(input_img)\n",
        "\n",
        "\n",
        "latent_input = layers.Input(shape=(latent_dim,))\n",
        "\n",
        "output_layer = layers.Dense(784, activation='relu')(latent_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3Wf9hzzWX1s"
      },
      "source": [
        "## Now, we build the encoder and decoder from the same layers.\n",
        "\n",
        "Let's start with the encoder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_YYpmzyWX1s"
      },
      "outputs": [],
      "source": [
        "# this model maps an input to its encoded representation\n",
        "encoder = tf.keras.models.Model(input_img, latent_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9GBri5sWX1s"
      },
      "source": [
        "Now, for the decoder. This requires slightly more work because we want to have a latent representation as an Input in order to use the decoder as a generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RSLRASgWX1t"
      },
      "outputs": [],
      "source": [
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "latent_input = layers.Input(shape=(latent_dim,))\n",
        "\n",
        "out = layers.Dense(784, activation='relu')(latent_input)\n",
        "decoder = tf.keras.models.Model(latent_input, out)\n",
        "\n",
        "\n",
        "# put the layers together to create your Model\n",
        "autoencoder = tf.keras.models.Model(input_img, decoder(encoder(input_img)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iKENJfFWX1t"
      },
      "source": [
        "### Build the model..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0SXQZ0yWX1u"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(lr = 0.0001)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecJJycYfWX1u"
      },
      "source": [
        "### Now, train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ndab-gXRWX1u"
      },
      "outputs": [],
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=40,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8G_AS2ybWX1v"
      },
      "outputs": [],
      "source": [
        "# encode and decode digits from the test det\n",
        "\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BcDD64tWX1v"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIuM4orWWX1w"
      },
      "source": [
        "\n",
        "### We can try k-means clustering on the latent space to see if we can separate numbers\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke4ivnznWX1w"
      },
      "outputs": [],
      "source": [
        "clust = KMeans(n_clusters=10).fit(encoded_imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckrKfvQ2WX1w"
      },
      "outputs": [],
      "source": [
        "print(clust.labels_)\n",
        "print(clust.predict(encoded_imgs))\n",
        "#print(clust.cluster_centers_)\n",
        "ind = np.where(clust.labels_ == 0)[0][:10]\n",
        "for i in ind:\n",
        "    plt.imshow(x_test[i].reshape((28,28)))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFk6Op6bWX1x"
      },
      "source": [
        "# AT-TPC data\n",
        "\n",
        "Now that you have some experience, try to build an autoencoder for the AT-TPC data! I am leaving this open-ended so that you can think through all of the necessary steps and choices.\n",
        "\n",
        "First, we load real and simulated data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Xm6z1z1WX1x"
      },
      "outputs": [],
      "source": [
        "(real_features, _), (sim_features, _) = load_attpc_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5w2-tcgWX1y"
      },
      "source": [
        "Let's remind ourselves of the shape of this data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEEegIfjWX1y"
      },
      "outputs": [],
      "source": [
        "print('Real Features:\\n   Shape: {}\\n   Type: {}\\n'.format(real_features.shape, real_features.dtype))\n",
        "print('Simulated Features:\\n   Shape: {}\\n   Type: {}\\n'.format(sim_features.shape, sim_features.dtype))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzZbMidVWX1y"
      },
      "source": [
        "If running this notebook on Google Colab, you may not be able to fit all 50,000 simulated events in RAM. Run the cell below to use only 10,000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDu1uOkdWX1y"
      },
      "outputs": [],
      "source": [
        "sim_features = sim_features[:10000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYUTdL8OWX1z"
      },
      "source": [
        "#### Experimental data\n",
        "\n",
        "We visualize the first 25 examples from the experimental dataset below. We no longer have class information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DahRNaoUWX1z"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(real_features[i], cmap='gray')\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdYpBK_CWX1z"
      },
      "source": [
        "#### Simulated data\n",
        "\n",
        "And now we again visualize the first 25 examples from the simulated dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-EZiszxWX1z"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(sim_features[i], cmap='gray')\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1_aDBrJWX10"
      },
      "source": [
        "### And now, I leave you to think through the next steps!\n",
        "\n",
        "*(Hint, don't forget to preprocess your data!)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DywU6i8WX10"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}